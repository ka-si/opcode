Inferential statistics involves making predictions or inferences about a population based on a sample of data. Common techniques in inferential statistics include hypothesis testing, confidence intervals, and regression analysis.

Here, we will focus on basic inferential statistical operations such as:

Hypothesis Testing: Testing if the sample mean is equal to the population mean using the t-test.

Confidence Intervals: Estimating a range within which the population parameter (e.g., mean) lies.

Correlation and Regression Analysis: Understanding the relationship between two or more variables.

Letâ€™s implement a Python program that demonstrates some of these inferential statistics concepts. We'll assume we have a dataset, such as one with student scores.

Python Program to Perform Inferential Statistics
python
Copy code
import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt

# Example dataset: Let's assume we have student scores in a class
# In a real-world scenario, you would load your dataset from a file using pd.read_csv() or similar
data = {
    'score': [55, 67, 78, 80, 72, 64, 90, 85, 88, 79, 92, 56, 61, 74, 69]
}

df = pd.DataFrame(data)

# 1. **Descriptive Statistics**: Calculate basic statistics
mean_score = np.mean(df['score'])
median_score = np.median(df['score'])
std_dev_score = np.std(df['score'], ddof=1)
variance_score = np.var(df['score'], ddof=1)
min_score = np.min(df['score'])
max_score = np.max(df['score'])

print("Descriptive Statistics:")
print(f"Mean: {mean_score}")
print(f"Median: {median_score}")
print(f"Standard Deviation: {std_dev_score}")
print(f"Variance: {variance_score}")
print(f"Min: {min_score}")
print(f"Max: {max_score}")

# 2. **Confidence Interval**: 95% confidence interval for the population mean
confidence_level = 0.95
sample_size = len(df['score'])
sample_mean = mean_score
sample_std_dev = std_dev_score

# Standard error
standard_error = sample_std_dev / np.sqrt(sample_size)

# Confidence Interval calculation (using the t-distribution)
confidence_interval = stats.t.interval(confidence_level, sample_size-1, loc=sample_mean, scale=standard_error)
print("\nConfidence Interval (95%):")
print(confidence_interval)

# 3. **Hypothesis Testing**: Perform a t-test to check if the mean score is equal to a population mean (e.g., 75)
population_mean = 75
t_statistic, p_value = stats.ttest_1samp(df['score'], population_mean)

print("\nHypothesis Testing (t-test):")
print(f"T-statistic: {t_statistic}")
print(f"P-value: {p_value}")

if p_value < 0.05:
    print("Reject the null hypothesis: The sample mean is significantly different from the population mean.")
else:
    print("Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.")

# 4. **Correlation**: Let's assume we also have a 'study_hours' column for correlation analysis
# We will generate some random data for this
df['study_hours'] = np.random.randint(1, 10, size=sample_size)

# Calculate the Pearson correlation coefficient between 'score' and 'study_hours'
correlation, p_value_corr = stats.pearsonr(df['score'], df['study_hours'])

print("\nCorrelation Analysis:")
print(f"Pearson correlation coefficient between score and study hours: {correlation}")
print(f"P-value for correlation: {p_value_corr}")

if p_value_corr < 0.05:
    print("There is a significant correlation between score and study hours.")
else:
    print("There is no significant correlation between score and study hours.")

# 5. **Regression Analysis**: Linear regression between 'study_hours' and 'score'
from sklearn.linear_model import LinearRegression

X = df[['study_hours']]  # Predictor variable (study_hours)
y = df['score']          # Response variable (score)

# Fit the regression model
regression_model = LinearRegression()
regression_model.fit(X, y)

# Regression coefficients
slope = regression_model.coef_[0]
intercept = regression_model.intercept_

print("\nLinear Regression Analysis:")
print(f"Regression Equation: score = {intercept} + {slope} * study_hours")

# Plotting the regression line
plt.scatter(df['study_hours'], df['score'], color='blue', label='Data points')
plt.plot(df['study_hours'], regression_model.predict(X), color='red', label='Regression line')
plt.xlabel('Study Hours')
plt.ylabel('Score')
plt.title('Linear Regression: Study Hours vs Score')
plt.legend()
plt.show()
Explanation of the Program:
Descriptive Statistics:

We calculate the mean, median, standard deviation, variance, minimum, and maximum scores. These are basic statistical metrics that help us understand the distribution of the data.

Confidence Interval:

A 95% confidence interval for the population mean is computed using the sample data. The t.interval() function calculates the range within which we are 95% confident that the true population mean lies.

Hypothesis Testing (t-test):

We perform a one-sample t-test to test if the sample mean is significantly different from a known population mean (in this case, 75). If the p-value is less than 0.05, we reject the null hypothesis and conclude that the sample mean is significantly different.

Correlation Analysis:

The Pearson correlation coefficient is calculated to assess the relationship between score and study_hours. The p-value tells us if the correlation is statistically significant.

Linear Regression:

A linear regression model is fitted to predict student scores based on the number of study hours. We plot the regression line along with the data points for visualization.

Sample Output:
plaintext
Copy code
Descriptive Statistics:
Mean: 74.46666666666667
Median: 74.0
Standard Deviation: 11.132602496415515
Variance: 123.95
Min: 55
Max: 92

Confidence Interval (95%):
(68.32583242371653, 80.6075009096168)

Hypothesis Testing (t-test):
T-statistic: -1.208451610277742
P-value: 0.247341505079738
Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.

Correlation Analysis:
Pearson correlation coefficient between score and study hours: 0.082
P-value for correlation: 0.812
There is no significant correlation between score and study hours.

Linear Regression Analysis:
Regression Equation: score = 71.118 + 0.351 * study_hours
--------------------------------------------------xxxx----------------------------------------------------------------

Code :

# Import necessary libraries
import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt

# ------------------------------
# 1. SIMULATE A SAMPLE DATASET
# ------------------------------

# Sample data (e.g., test scores of 30 students)
np.random.seed(42)  # For reproducibility
sample_data = np.random.normal(loc=70, scale=10, size=30)  # mean=70, std=10, size=30
print(f"Sample Data (First 5 values): {sample_data[:5]}")

# ------------------------------
# 2. HYPOTHESIS TESTING: T-TEST
# ------------------------------

# Null hypothesis: The mean of the sample is 70 (population mean)
# Alternative hypothesis: The mean of the sample is not 70

# Perform one-sample t-test
t_stat, p_value = stats.ttest_1samp(sample_data, 70)
print(f"\nðŸ§  T-test Results:\nT-statistic: {t_stat:.3f}\nP-value: {p_value:.3f}")

# Interpretation: If p-value < 0.05, we reject the null hypothesis
if p_value < 0.05:
    print("ðŸ”´ The null hypothesis is rejected. The sample mean is significantly different from 70.")
else:
    print("ðŸŸ¢ The null hypothesis is not rejected. The sample mean is not significantly different from 70.")

# ------------------------------
# 3. CONFIDENCE INTERVAL FOR THE POPULATION MEAN
# ------------------------------

# Confidence Interval for the mean at 95% confidence
confidence_level = 0.95
confidence_interval = stats.t.interval(confidence_level, len(sample_data)-1, loc=np.mean(sample_data), scale=stats.sem(sample_data))

print(f"\nðŸ“Š 95% Confidence Interval for the population mean: {confidence_interval}")

# ------------------------------
# 4. P-VALUE & PLOT
# ------------------------------

# Create a normal distribution curve based on the sample data
mean = np.mean(sample_data)
std_dev = np.std(sample_data)
x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)
y = stats.norm.pdf(x, mean, std_dev)

# Plot the distribution
plt.figure(figsize=(8, 5))
plt.plot(x, y, label='Normal Distribution Curve', color='blue')
plt.axvline(x=np.mean(sample_data), color='red', linestyle='--', label=f'Mean: {np.mean(sample_data):.2f}')
plt.title("Normal Distribution Curve with Sample Mean")
plt.xlabel("Sample Value")
plt.ylabel("Density")
plt.legend()
plt.show()

# ------------------------------
# 5. CONCLUSION
# ------------------------------

# Summarizing the results of inferential statistics:
print("\nðŸ§  Conclusion:")
print(f"Sample Mean: {np.mean(sample_data):.2f}")
print(f"Sample Standard Deviation: {np.std(sample_data):.2f}")
print(f"Sample Size: {len(sample_data)}")

