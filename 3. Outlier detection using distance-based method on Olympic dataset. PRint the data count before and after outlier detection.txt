Aim: Outlier detection using distance-based method on Olympic dataset. Print the data count before and after outlier detection.

âœ… THEORY
ðŸ”¹ What Are Outliers?
Outliers are data points that deviate significantly from other observations. They can:

Skew results

Affect model performance

Indicate data entry errors or rare events

ðŸ”¹ Distance-Based Outlier Detection
This method identifies outliers by measuring the distance between a point and its neighbors. A data point is considered an outlier if:

It has few neighbors within a certain distance threshold, or

Its distance to the k-nearest neighbors (k-NN) is unusually high

This method is unsupervised and works well for numerical multivariate data like Age, Height, Weight in Olympic datasets.

ðŸ”¹ Common Distance-Based Methods
Euclidean Distance

Mahalanobis Distance

k-Nearest Neighbors (k-NN) Distance

âœ… IMPLEMENTATION STEPS
Load the Olympic dataset

Select numerical features (e.g., Age, Height, Weight)

Normalize/Standardize the data

Use k-NN distance (e.g., with sklearn.neighbors.NearestNeighbors)

Mark top N farthest points as outliers (e.g., top 5% farthest)

Remove those outliers

Print data shape before and after

âœ… PSEUDO CODE (Python Style)
python
Copy code
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors

# Step 1: Load the dataset
df = pd.read_csv("olympic_dataset.csv")

# Step 2: Select numerical features for outlier detection
numerical_cols = ['Age', 'Height', 'Weight']
data = df[numerical_cols].dropna()

# Store original shape
original_count = data.shape[0]

# Step 3: Normalize the data
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Step 4: Use Nearest Neighbors to compute distances
k = 5
nn = NearestNeighbors(n_neighbors=k)
nn.fit(data_scaled)
distances, _ = nn.kneighbors(data_scaled)

# Average distance to k-neighbors
avg_distances = distances.mean(axis=1)

# Step 5: Define outliers as top 5% points with largest average distance
threshold = np.percentile(avg_distances, 95)
outliers = avg_distances > threshold

# Step 6: Filter out the outliers
data_cleaned = data[~outliers]

# Step 7: Print count before and after
print("Data count before outlier removal:", original_count)
print("Data count after outlier removal:", data_cleaned.shape[0])

------------------------------xxx--------------------------------------
code :

# Import necessary libraries
import pandas as pd
import numpy as np
from scipy.stats import zscore
from scipy.spatial.distance import mahalanobis

# ------------------------------
# LOADING DATA
# ------------------------------

# Option 1: Load from URL (use your actual dataset URL if different)
url = 'https://raw.githubusercontent.com/datablist/sample-csv-files/main/files/people/olympic_athletes.csv'
try:
    olympic_data_url = pd.read_csv(url)
    print("Data loaded from URL.\n")
except Exception as e:
    print("URL loading error:", e)

# Option 2: Load from local CSV
try:
    olympic_data_csv = pd.read_csv('olympic_data.csv')
    print("Data loaded from local file.\n")
except Exception as e:
    print("CSV loading error:", e)

# Use whichever loaded successfully
df = olympic_data_url.copy()

# ------------------------------
# DATA PREPROCESSING
# ------------------------------

# Select only numerical columns for distance-based analysis
numerical_df = df.select_dtypes(include=[np.number])

# Drop rows with missing values for clean computation
numerical_df_clean = numerical_df.dropna()

print("Initial data count:", numerical_df_clean.shape[0])

# ------------------------------
# METHOD 1: Z-SCORE OUTLIER DETECTION
# ------------------------------

# Calculate z-scores
z_scores = np.abs(zscore(numerical_df_clean))

# Set a threshold (commonly 3 for outliers)
threshold = 3

# Identify rows where any column has a z-score above the threshold
non_outliers = (z_scores < threshold).all(axis=1)

# Filter the data
df_no_outliers = numerical_df_clean[non_outliers]

print("Data count after removing outliers (Z-score method):", df_no_outliers.shape[0])

# ------------------------------
# OPTIONAL: METHOD 2 - Mahalanobis Distance (for multivariate outliers)
# ------------------------------

# # Compute mean and covariance matrix
# mean = np.mean(numerical_df_clean, axis=0)
# cov = np.cov(numerical_df_clean.values.T)
# inv_cov = np.linalg.inv(cov)

# # Mahalanobis distance for each row
# distances = numerical_df_clean.apply(lambda row: mahalanobis(row, mean, inv_cov), axis=1)

# # Define threshold (can use chi-squared distribution if precise)
# mahal_threshold = np.percentile(distances, 95)

# # Filter based on Mahalanobis distance
# df_mahal_filtered = numerical_df_clean[distances < mahal_threshold]
# print("Data count after Mahalanobis filtering:", df_mahal_filtered.shape[0])

